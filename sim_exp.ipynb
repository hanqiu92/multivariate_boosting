{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Experiments of mbst and Projected mbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanqiu/anaconda3/lib/python3.6/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "## mbst objects\n",
    "from mbst import *\n",
    "## training functions\n",
    "from train import *\n",
    "## functions generating experiment cases\n",
    "from exp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "N_sample = 100000 ## sample size\n",
    "N_feats = 10 ## number of feature\n",
    "N_trees_real = 100 ## number of boosted trees in the random mbst\n",
    "\n",
    "np.random.seed(32) ## fixed seed for replications\n",
    "\n",
    "## different specifications of base effect and treatment effects\n",
    "exp_case = 1\n",
    "if exp_case == 1:\n",
    "    ## 1 * base effect + 0.25 * treatment effect\n",
    "    theta_dim = 2\n",
    "    theta_factors = np.array([1,0.25])\n",
    "    base_effect_flag = True\n",
    "elif exp_case == 2:\n",
    "    ## 1 * base effect + 1 * treatment effect\n",
    "    theta_dim = 2\n",
    "    theta_factors = np.array([1,1])\n",
    "    base_effect_flag = True\n",
    "elif exp_case == 3:\n",
    "    ## 1 * treatment effect (1) + 0.5 * treatment effect (2)\n",
    "    theta_dim = 2\n",
    "    theta_factors = np.array([1,0.5])\n",
    "    base_effect_flag = False\n",
    "elif exp_case == 4:\n",
    "    ## 1 * base effect + 1 * treatment effect (1) + 0.5 * treatment effect (2)\n",
    "    theta_dim = 3\n",
    "    theta_factors = np.array([1,1,0.5])\n",
    "    base_effect_flag = True\n",
    "elif exp_case == 5:\n",
    "    ## 1 * base effect + 0.5 * treatment effect (1) + 0.25 * treatment effect (2)\n",
    "    theta_dim = 3\n",
    "    theta_factors = np.array([1,0.5,0.25])\n",
    "    base_effect_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## generate experiment data according to parameters above\n",
    "feat_list = [str(i) for i in range(N_feats)]\n",
    "feat_dict = dict([(feat,idx) for idx,feat in enumerate(feat_list)])\n",
    "X_ext = np.random.normal(size=(N_sample,len(feat_list)))\n",
    "df_ext = pd.DataFrame(X_ext,columns=feat_list)\n",
    "X_treat = np.random.normal(size=(N_sample,theta_dim))\n",
    "if base_effect_flag:\n",
    "    X_treat[:,0] = 1\n",
    "_,_,splits_dict = find_splits_dict(df_ext,feat_list)\n",
    "mbst_real = generate_random_theta_mbst(N_trees_real,feat_list,splits_dict,theta_dim,theta_factors)\n",
    "theta_real = mbst_real.predict(X_ext,feat_dict)\n",
    "y_real = np.sum(X_treat * theta_real,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying different estimation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. setting common training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_trees_train = 300 ## number of boosted trees during training\n",
    "N_train = int(N_sample * 0.7) ## training samples\n",
    "\n",
    "params = {'lam_reg':1,\n",
    "          'learning_rate':0.1,\n",
    "          'max_depth':4,\n",
    "          'min_split_loss':0,\n",
    "          'subsample':0.7,\n",
    "          'min_childs':10}\n",
    "\n",
    "params_xgb = {'reg_lambda':params.get('lam_reg',1),\n",
    "              'learning_rate':params.get('learning_rate',0.1),\n",
    "              'max_depth':params.get('max_depth',4),\n",
    "              'subsample':params.get('subsample',0.7),\n",
    "              'objective':'reg:squarederror'}\n",
    "\n",
    "def linear_obj(theta,labels):\n",
    "    ## MSE loss and corresponding grad / hess\n",
    "    X_treat,y = labels\n",
    "    y_pred = np.sum(X_treat*theta,axis=-1)\n",
    "    ll = np.square(y_pred - y)\n",
    "    loss = np.sqrt(np.mean(ll))\n",
    "    grad = (y_pred - y).reshape((-1,1)) * X_treat\n",
    "    hess = np.expand_dims(X_treat,axis=1) * np.expand_dims(X_treat,axis=2)\n",
    "    return loss,grad,hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.vanilla xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 5.74s.\n",
      "y predict time: 0.14s.\n",
      "theta predict time: 15.99s.\n"
     ]
    }
   ],
   "source": [
    "X_all = np.concatenate([X_ext,X_treat],axis=-1)\n",
    "xg_dtrain = xgb.DMatrix(X_all[:N_train],label=y_real[:N_train])\n",
    "xg_dall = xgb.DMatrix(X_all,label=y_real)\n",
    "\n",
    "tt = time.time()\n",
    "xgb_bst = xgb.train(params_xgb,xg_dtrain,num_boost_round=N_trees_train,verbose_eval=False)\n",
    "print('train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "tt = time.time()\n",
    "y_pred = xgb_bst.predict(xg_dall)\n",
    "print('y predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "tt = time.time()\n",
    "X_all_new = np.concatenate([X_ext,X_treat],axis=-1)\n",
    "\n",
    "N_treat_sample = 100 ## for local linear regression\n",
    "X_treat_samples = X_treat[np.random.choice(len(X_treat),N_treat_sample,replace=False)]\n",
    "y_pred_new = []\n",
    "for X_treat_sample in X_treat_samples:\n",
    "    X_all_new[:,-theta_dim:] = X_treat_sample\n",
    "    y_pred_new.append(xgb_bst.predict(xgb.DMatrix(X_all_new)))\n",
    "y_pred_new = np.stack(y_pred_new,axis=0)\n",
    "A = np.matmul(X_treat_samples.T,X_treat_samples)\n",
    "b = np.matmul(X_treat_samples.T,y_pred_new)\n",
    "theta_pred = np.linalg.solve(A,b).T\n",
    "print('theta predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "theta_pred_xgb_base,y_pred_xgb_base = theta_pred,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. multi-stage xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 0 train time: 3.06s.\n",
      "stage 0 predict time: 0.07s.\n",
      "stage 1 train time: 3.06s.\n",
      "stage 1 predict time: 0.07s.\n"
     ]
    }
   ],
   "source": [
    "X_ext_train = X_ext[:N_train]\n",
    "X_treat_train = X_treat[:N_train]\n",
    "y_remain_train = y_real[:N_train].copy()\n",
    "xg_dall = xgb.DMatrix(X_ext)\n",
    "\n",
    "theta_pred = []\n",
    "for iter_ in range(theta_dim):\n",
    "    header = 'stage {} '.format(iter_)\n",
    "    w = X_treat_train[:,iter_]\n",
    "    valid_idxs = (np.abs(w) > 1e-3)\n",
    "    xg_dtrain = xgb.DMatrix(X_ext_train[valid_idxs],label=y_remain_train[valid_idxs]/w[valid_idxs],\n",
    "                            weight=w[valid_idxs]**2)\n",
    "    \n",
    "    tt = time.time()\n",
    "    xgb_bst = xgb.train(params_xgb,xg_dtrain,\n",
    "                        num_boost_round=int(N_trees_train // theta_dim) + 1,verbose_eval=False)\n",
    "    print(header + 'train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "    tt = time.time()\n",
    "    theta_iter_pred = xgb_bst.predict(xg_dall)\n",
    "    theta_pred.append(theta_iter_pred)\n",
    "    y_remain_train -= w * theta_iter_pred[:N_train]\n",
    "    print(header + 'predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "    \n",
    "theta_pred = np.stack(theta_pred,axis=-1)\n",
    "y_pred = np.sum(X_treat*theta_pred,axis=-1)\n",
    "\n",
    "theta_pred_xgb_mstage,y_pred_xgb_mstage = theta_pred,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. grf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "from rpy2.robjects import r as rapi\n",
    "numpy2ri.activate()\n",
    "grf = importr('grf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 0 train time: 17.75s.\n",
      "stage 0 predict time: 3.61s.\n",
      "stage 1 train time: 46.80s.\n",
      "stage 1 predict time: 2.95s.\n"
     ]
    }
   ],
   "source": [
    "X_ext_train = X_ext[:N_train]\n",
    "X_treat_train = X_treat[:N_train]\n",
    "y_remain_train = np.expand_dims(y_real[:N_train].copy(),axis=-1)\n",
    "\n",
    "theta_pred = []\n",
    "for iter_ in range(theta_dim):\n",
    "    header = 'stage {} '.format(iter_)\n",
    "    w = X_treat_train[:,[iter_]]\n",
    "    valid_idxs = (np.abs(w[:,0]) > 1e-3)\n",
    "    \n",
    "    tt = time.time()\n",
    "    if np.std(w) < 1e-3:\n",
    "        grf_bst = grf.regression_forest(X_ext_train[valid_idxs],y_remain_train[valid_idxs],\n",
    "                               num_trees=int(N_trees_train // theta_dim) + 1)\n",
    "    else:\n",
    "        grf_bst = grf.causal_forest(X_ext_train[valid_idxs],y_remain_train[valid_idxs],\n",
    "                               w[valid_idxs],num_trees=int(N_trees_train // theta_dim) + 1)\n",
    "    print(header + 'train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "    tt = time.time()\n",
    "    theta_iter_pred = rapi.predict(grf_bst,X_ext)['predictions']\n",
    "    theta_pred.append(theta_iter_pred)\n",
    "    y_remain_train -= w * np.expand_dims(theta_iter_pred[:N_train],axis=-1)\n",
    "    print(header + 'predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "    \n",
    "theta_pred = np.stack(theta_pred,axis=-1)\n",
    "y_pred = np.sum(X_treat*theta_pred,axis=-1)\n",
    "\n",
    "theta_pred_grf,y_pred_grf = theta_pred,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. mbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 131.89s.\n",
      "predict time: 2.43s.\n"
     ]
    }
   ],
   "source": [
    "tt = time.time()\n",
    "mbst,_ = train_multi_bst(params,df_ext.iloc[:N_train].copy(),labels=(X_treat[:N_train],y_real[:N_train]),\n",
    "                         feat_list=feat_list,num_boost_round=N_trees_train,\n",
    "                         obj_func=linear_obj,verbose=False)\n",
    "print('train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "tt = time.time()\n",
    "theta_pred = mbst.predict(X_ext,feat_dict)\n",
    "y_pred = np.sum(X_treat*theta_pred,axis=-1)\n",
    "print('predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "theta_pred_mbst,y_pred_mbst = theta_pred,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. projected mbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, define a variety of direction finding methods\n",
    "def find_direc_func_null(grad,hess,grad_func,mbst,train_info):\n",
    "    dim = grad.shape[-1]\n",
    "    direc = np.ones((dim,)) / dim\n",
    "    return direc\n",
    "\n",
    "def find_direc_func_grad(grad,hess,grad_func,mbst,train_info):\n",
    "    direc = find_max_var_direc(grad)\n",
    "    return direc\n",
    "\n",
    "def find_direc_func_approx(grad,hess,grad_func,mbst,train_info):\n",
    "    H_sum = np.sum(hess,axis=0)\n",
    "    dtheta_est = np.linalg.solve(H_sum,grad.T).T\n",
    "    direc = find_max_var_direc(dtheta_est)\n",
    "    return direc\n",
    "\n",
    "def find_direc_func_nag(grad,hess,grad_func,mbst,train_info,moment_beta=0.9):\n",
    "    moment = moment_beta * train_info.get('grad_prev',np.zeros(grad.shape))\n",
    "    grad_new,hess_new = grad_func(train_info.get('curr_theta',np.zeros(grad.shape)) \\\n",
    "                                  + train_info.get('delta_theta_mean',np.zeros(grad.shape)) \\\n",
    "                                  + moment * mbst.learning_rate)\n",
    "    grad_new = grad_new + moment\n",
    "    direc = find_max_var_direc(grad_new)\n",
    "    return direc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project mbst (n,c,g)\n",
      "train time: 46.94s.\n",
      "predict time: 2.68s.\n",
      "project mbst (n,c,hg)\n",
      "train time: 50.17s.\n",
      "predict time: 2.46s.\n",
      "project mbst (n,c,nag)\n",
      "train time: 52.90s.\n",
      "predict time: 3.03s.\n",
      "project mbst (pc,c,g)\n",
      "train time: 107.54s.\n",
      "predict time: 2.46s.\n",
      "project mbst (pc,c,hg)\n",
      "train time: 101.84s.\n",
      "predict time: 2.50s.\n",
      "project mbst (pc,c,nag)\n",
      "train time: 104.65s.\n",
      "predict time: 2.45s.\n"
     ]
    }
   ],
   "source": [
    "mbst_projs = []\n",
    "theta_pred_projs = []\n",
    "y_pred_projs = []\n",
    "name_projs = []\n",
    "\n",
    "find_direc_funcs = [\n",
    "#                  ('n',find_direc_func_null),\n",
    "                 ('g',find_direc_func_grad),\n",
    "                ('hg',find_direc_func_approx),\n",
    "                 ('nag',find_direc_func_nag),\n",
    "                ]\n",
    "\n",
    "## then, iterate all possible projected mbst options\n",
    "for corrected_name,corrected in [('n',False),('pc',True)]:\n",
    "#     for centered in [('nc',False),('c',True)]:\n",
    "    for centered_name,centered in [('c',True)]:\n",
    "        for direc_name,find_direc_func in (find_direc_funcs):\n",
    "            name = 'project mbst ({},{},{})'.format(corrected_name,centered_name,direc_name)\n",
    "            print(name)\n",
    "            \n",
    "            tt = time.time()\n",
    "            mbst,_ = train_project_bst(params,df_ext.iloc[:N_train].copy(),\n",
    "                                     labels=(X_treat[:N_train],y_real[:N_train]),\n",
    "                                     feat_list=feat_list,num_boost_round=N_trees_train,\n",
    "                                       find_direc_func=find_direc_func,\n",
    "                                       corrected=corrected,centered=centered,\n",
    "                                     obj_func=linear_obj,verbose=False)\n",
    "            print('train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "            tt = time.time()\n",
    "            theta_pred = mbst.predict(X_ext,feat_dict)\n",
    "            y_pred = np.sum(X_treat*theta_pred,axis=-1)\n",
    "            print('predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "            \n",
    "            name_projs.append(name)\n",
    "            mbst_projs.append(mbst)\n",
    "            theta_pred_projs.append(theta_pred)\n",
    "            y_pred_projs.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean baseline</th>\n",
       "      <th>xgb</th>\n",
       "      <th>multi-stage xgb</th>\n",
       "      <th>grf</th>\n",
       "      <th>mbst</th>\n",
       "      <th>project mbst (n,c,g)</th>\n",
       "      <th>project mbst (n,c,hg)</th>\n",
       "      <th>project mbst (n,c,nag)</th>\n",
       "      <th>project mbst (pc,c,g)</th>\n",
       "      <th>project mbst (pc,c,hg)</th>\n",
       "      <th>project mbst (pc,c,nag)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y rmse train</th>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y rmse test</th>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.0329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta rmse train</th>\n",
       "      <td>[0.0836, 0.0224]</td>\n",
       "      <td>[0.028, 0.0152]</td>\n",
       "      <td>[0.033, 0.009]</td>\n",
       "      <td>[0.041, 0.0139]</td>\n",
       "      <td>[0.0268, 0.0099]</td>\n",
       "      <td>[0.0339, 0.0089]</td>\n",
       "      <td>[0.0387, 0.0092]</td>\n",
       "      <td>[0.0344, 0.0088]</td>\n",
       "      <td>[0.031, 0.0089]</td>\n",
       "      <td>[0.0312, 0.0089]</td>\n",
       "      <td>[0.0309, 0.0089]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta rmse test</th>\n",
       "      <td>[0.0831, 0.0224]</td>\n",
       "      <td>[0.0288, 0.0153]</td>\n",
       "      <td>[0.0338, 0.0092]</td>\n",
       "      <td>[0.0454, 0.0141]</td>\n",
       "      <td>[0.0275, 0.01]</td>\n",
       "      <td>[0.0343, 0.0091]</td>\n",
       "      <td>[0.039, 0.0093]</td>\n",
       "      <td>[0.0348, 0.009]</td>\n",
       "      <td>[0.0316, 0.0091]</td>\n",
       "      <td>[0.0318, 0.009]</td>\n",
       "      <td>[0.0316, 0.0091]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta corr train</th>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[0.9439, 0.7777]</td>\n",
       "      <td>[0.9227, 0.9189]</td>\n",
       "      <td>[0.8816, 0.8187]</td>\n",
       "      <td>[0.9489, 0.8985]</td>\n",
       "      <td>[0.9174, 0.9182]</td>\n",
       "      <td>[0.8904, 0.9132]</td>\n",
       "      <td>[0.9149, 0.9198]</td>\n",
       "      <td>[0.9312, 0.9193]</td>\n",
       "      <td>[0.9305, 0.92]</td>\n",
       "      <td>[0.9319, 0.9202]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta corr test</th>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>[0.9394, 0.7778]</td>\n",
       "      <td>[0.9177, 0.9155]</td>\n",
       "      <td>[0.8441, 0.8086]</td>\n",
       "      <td>[0.945, 0.8965]</td>\n",
       "      <td>[0.914, 0.9154]</td>\n",
       "      <td>[0.887, 0.9109]</td>\n",
       "      <td>[0.9111, 0.9167]</td>\n",
       "      <td>[0.9274, 0.9162]</td>\n",
       "      <td>[0.9265, 0.9172]</td>\n",
       "      <td>[0.9277, 0.9161]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mean baseline               xgb   multi-stage xgb  \\\n",
       "y rmse train                0.0869            0.0312            0.0333   \n",
       "y rmse test                 0.0865            0.0328             0.035   \n",
       "theta rmse train  [0.0836, 0.0224]   [0.028, 0.0152]    [0.033, 0.009]   \n",
       "theta rmse test   [0.0831, 0.0224]  [0.0288, 0.0153]  [0.0338, 0.0092]   \n",
       "theta corr train        [0.0, 0.0]  [0.9439, 0.7777]  [0.9227, 0.9189]   \n",
       "theta corr test         [0.0, 0.0]  [0.9394, 0.7778]  [0.9177, 0.9155]   \n",
       "\n",
       "                               grf              mbst project mbst (n,c,g)  \\\n",
       "y rmse train                0.0416             0.028                0.034   \n",
       "y rmse test                 0.0476            0.0293               0.0355   \n",
       "theta rmse train   [0.041, 0.0139]  [0.0268, 0.0099]     [0.0339, 0.0089]   \n",
       "theta rmse test   [0.0454, 0.0141]    [0.0275, 0.01]     [0.0343, 0.0091]   \n",
       "theta corr train  [0.8816, 0.8187]  [0.9489, 0.8985]     [0.9174, 0.9182]   \n",
       "theta corr test   [0.8441, 0.8086]   [0.945, 0.8965]      [0.914, 0.9154]   \n",
       "\n",
       "                 project mbst (n,c,hg) project mbst (n,c,nag)  \\\n",
       "y rmse train                    0.0385                 0.0344   \n",
       "y rmse test                     0.0401                  0.036   \n",
       "theta rmse train      [0.0387, 0.0092]       [0.0344, 0.0088]   \n",
       "theta rmse test        [0.039, 0.0093]        [0.0348, 0.009]   \n",
       "theta corr train      [0.8904, 0.9132]       [0.9149, 0.9198]   \n",
       "theta corr test        [0.887, 0.9109]       [0.9111, 0.9167]   \n",
       "\n",
       "                 project mbst (pc,c,g) project mbst (pc,c,hg)  \\\n",
       "y rmse train                    0.0315                 0.0316   \n",
       "y rmse test                     0.0329                 0.0331   \n",
       "theta rmse train       [0.031, 0.0089]       [0.0312, 0.0089]   \n",
       "theta rmse test       [0.0316, 0.0091]        [0.0318, 0.009]   \n",
       "theta corr train      [0.9312, 0.9193]         [0.9305, 0.92]   \n",
       "theta corr test       [0.9274, 0.9162]       [0.9265, 0.9172]   \n",
       "\n",
       "                 project mbst (pc,c,nag)  \n",
       "y rmse train                      0.0313  \n",
       "y rmse test                       0.0329  \n",
       "theta rmse train        [0.0309, 0.0089]  \n",
       "theta rmse test         [0.0316, 0.0091]  \n",
       "theta corr train        [0.9319, 0.9202]  \n",
       "theta corr test         [0.9277, 0.9161]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rounding(l,decimals=4):\n",
    "    return list(np.round(l,decimals=decimals))\n",
    "\n",
    "method_names = ['mean baseline','xgb','multi-stage xgb','grf','mbst'] + name_projs\n",
    "y_preds = [np.mean(y_real),y_pred_xgb_base,y_pred_xgb_mstage,y_pred_grf,y_pred_mbst] + y_pred_projs\n",
    "theta_preds = [np.mean(theta_real,axis=0),theta_pred_xgb_base,theta_pred_xgb_mstage,\n",
    "               theta_pred_grf,theta_pred_mbst] \\\n",
    "                + theta_pred_projs\n",
    "\n",
    "y_train_rmse = [np.sqrt(np.mean(np.square(y_pred - y_real)[:N_train])) for y_pred in y_preds]\n",
    "y_test_rmse = [np.sqrt(np.mean(np.square(y_pred - y_real)[N_train:])) for y_pred in y_preds]\n",
    "theta_train_rmse = [np.sqrt(np.mean(np.square(theta_pred - theta_real)[:N_train],axis=0)) \n",
    "                    for theta_pred in theta_preds]\n",
    "theta_test_rmse = [np.sqrt(np.mean(np.square(theta_pred - theta_real)[N_train:],axis=0)) \n",
    "                   for theta_pred in theta_preds]\n",
    "theta_train_corr = [np.zeros((theta_dim,))] + \\\n",
    "                    [np.array([np.corrcoef(theta_pred[:,col][:N_train], \n",
    "                                          theta_real[:,col][:N_train])[0,1] for col in range(theta_dim)]) \n",
    "                    for theta_pred in theta_preds[1:]]\n",
    "theta_test_corr = [np.zeros((theta_dim,))] + \\\n",
    "                    [np.array([np.corrcoef(theta_pred[:,col][N_train:], \n",
    "                                          theta_real[:,col][N_train:])[0,1] for col in range(theta_dim)]) \n",
    "                    for theta_pred in theta_preds[1:]]\n",
    "\n",
    "err_df = pd.DataFrame({'y rmse train':rounding(y_train_rmse),'y rmse test':rounding(y_test_rmse),\n",
    "                   'theta rmse train':rounding(theta_train_rmse),'theta rmse test':rounding(theta_test_rmse),\n",
    "                   'theta corr train':rounding(theta_train_corr),'theta corr test':rounding(theta_test_corr),})\n",
    "err_df = err_df.T\n",
    "err_df.columns = method_names\n",
    "display(err_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
