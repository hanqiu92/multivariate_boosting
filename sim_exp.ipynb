{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Experiments of mbst and Projected mbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanqiu/anaconda3/lib/python3.6/site-packages/dask/dataframe/utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "## mbst objects\n",
    "from mbst import *\n",
    "## training functions\n",
    "from train import *\n",
    "## functions generating experiment cases\n",
    "from exp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "N_sample = 100000 ## sample size\n",
    "N_feats = 10 ## number of feature\n",
    "N_trees_real = 100 ## number of boosted trees in the random mbst\n",
    "\n",
    "np.random.seed(32) ## fixed seed for replications\n",
    "\n",
    "## different specifications of base effect and treatment effects\n",
    "exp_case = 7\n",
    "if exp_case == 1:\n",
    "    ## 1 * base effect + 0.25 * treatment effect\n",
    "    theta_dim = 2\n",
    "    theta_factors = np.array([1,0.25])\n",
    "    base_effect_flag = True\n",
    "elif exp_case == 2:\n",
    "    ## 1 * base effect + 1 * treatment effect\n",
    "    theta_dim = 2\n",
    "    theta_factors = np.array([1,1])\n",
    "    base_effect_flag = True\n",
    "elif exp_case == 3:\n",
    "    ## 1 * treatment effect (1) + 0.5 * treatment effect (2)\n",
    "    theta_dim = 2\n",
    "    theta_factors = np.array([1,0.5])\n",
    "    base_effect_flag = False\n",
    "elif exp_case == 4:\n",
    "    ## 1 * base effect + 1 * treatment effect (1) + 0.5 * treatment effect (2)\n",
    "    theta_dim = 3\n",
    "    theta_factors = np.array([1,1,0.5])\n",
    "    base_effect_flag = True\n",
    "elif exp_case == 5:\n",
    "    ## 1 * base effect + 0.5 * treatment effect (1) + 0.25 * treatment effect (2)\n",
    "    theta_dim = 3\n",
    "    theta_factors = np.array([1,0.5,0.25])\n",
    "    base_effect_flag = True\n",
    "elif exp_case == 6:\n",
    "    ## 1 * base effect + 0.5 * treatment effect (1) + 1 * treatment effect (2)\n",
    "    theta_dim = 3\n",
    "    theta_factors = np.array([1,0.5,1])\n",
    "    base_effect_flag = True\n",
    "elif exp_case == 7:\n",
    "    ## 0.25 * treatment effect (1) + 1 * treatment effect (2) + 0.5 * treatment effect (3)\n",
    "    theta_dim = 3\n",
    "    theta_factors = np.array([0.25,1,0.5])\n",
    "    base_effect_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## generate experiment data according to parameters above\n",
    "feat_list = [str(i) for i in range(N_feats)]\n",
    "feat_dict = dict([(feat,idx) for idx,feat in enumerate(feat_list)])\n",
    "X_ext = np.random.normal(size=(N_sample,len(feat_list)))\n",
    "df_ext = pd.DataFrame(X_ext,columns=feat_list)\n",
    "X_treat = np.random.normal(size=(N_sample,theta_dim))\n",
    "if base_effect_flag:\n",
    "    X_treat[:,0] = 1\n",
    "_,_,splits_dict = find_splits_dict(df_ext,feat_list)\n",
    "mbst_real = generate_random_theta_mbst(N_trees_real,feat_list,splits_dict,theta_dim,theta_factors)\n",
    "theta_real = mbst_real.predict(X_ext,feat_dict)\n",
    "y_real = np.sum(X_treat * theta_real,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### applying different estimation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. setting common training params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_trees_train = 300 ## number of boosted trees during training\n",
    "N_train = int(N_sample * 0.7) ## training samples\n",
    "\n",
    "params = {'lam_reg':1,\n",
    "          'learning_rate':0.1,\n",
    "          'max_depth':4,\n",
    "          'min_split_loss':0,\n",
    "          'subsample':0.7,\n",
    "          'min_childs':10}\n",
    "\n",
    "params_xgb = {'reg_lambda':params.get('lam_reg',1),\n",
    "              'learning_rate':params.get('learning_rate',0.1),\n",
    "              'max_depth':params.get('max_depth',4),\n",
    "              'subsample':params.get('subsample',0.7),\n",
    "              'objective':'reg:squarederror'}\n",
    "\n",
    "def linear_obj(theta,labels):\n",
    "    ## MSE loss and corresponding grad / hess\n",
    "    X_treat,y = labels\n",
    "    y_pred = np.sum(X_treat*theta,axis=-1)\n",
    "    ll = np.square(y_pred - y)\n",
    "    loss = np.sqrt(np.mean(ll))\n",
    "    grad = (y_pred - y).reshape((-1,1)) * X_treat\n",
    "    hess = np.expand_dims(X_treat,axis=1) * np.expand_dims(X_treat,axis=2)\n",
    "    return loss,grad,hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.vanilla xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 7.24s.\n",
      "y predict time: 0.15s.\n",
      "theta predict time: 14.13s.\n"
     ]
    }
   ],
   "source": [
    "X_all = np.concatenate([X_ext,X_treat],axis=-1)\n",
    "xg_dtrain = xgb.DMatrix(X_all[:N_train],label=y_real[:N_train])\n",
    "xg_dall = xgb.DMatrix(X_all,label=y_real)\n",
    "\n",
    "tt = time.time()\n",
    "xgb_bst = xgb.train(params_xgb,xg_dtrain,num_boost_round=N_trees_train,verbose_eval=False)\n",
    "print('train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "tt = time.time()\n",
    "y_pred = xgb_bst.predict(xg_dall)\n",
    "print('y predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "tt = time.time()\n",
    "X_all_new = np.concatenate([X_ext,X_treat],axis=-1)\n",
    "\n",
    "N_treat_sample = 100 ## for local linear regression\n",
    "X_treat_samples = X_treat[np.random.choice(len(X_treat),N_treat_sample,replace=False)]\n",
    "y_pred_new = []\n",
    "for X_treat_sample in X_treat_samples:\n",
    "    X_all_new[:,-theta_dim:] = X_treat_sample\n",
    "    y_pred_new.append(xgb_bst.predict(xgb.DMatrix(X_all_new)))\n",
    "y_pred_new = np.stack(y_pred_new,axis=0)\n",
    "A = np.matmul(X_treat_samples.T,X_treat_samples)\n",
    "b = np.matmul(X_treat_samples.T,y_pred_new)\n",
    "theta_pred = np.linalg.solve(A,b).T\n",
    "print('theta predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "theta_pred_xgb_base,y_pred_xgb_base = theta_pred,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. multi-stage xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 0 train time: 2.20s.\n",
      "stage 0 predict time: 0.06s.\n",
      "stage 1 train time: 2.34s.\n",
      "stage 1 predict time: 0.07s.\n",
      "stage 2 train time: 2.28s.\n",
      "stage 2 predict time: 0.06s.\n"
     ]
    }
   ],
   "source": [
    "X_ext_train = X_ext[:N_train]\n",
    "X_treat_train = X_treat[:N_train]\n",
    "y_remain_train = y_real[:N_train].copy()\n",
    "xg_dall = xgb.DMatrix(X_ext)\n",
    "\n",
    "theta_pred = []\n",
    "for iter_ in range(theta_dim):\n",
    "    header = 'stage {} '.format(iter_)\n",
    "    w = X_treat_train[:,iter_]\n",
    "    valid_idxs = (np.abs(w) > 1e-3)\n",
    "    xg_dtrain = xgb.DMatrix(X_ext_train[valid_idxs],label=y_remain_train[valid_idxs]/w[valid_idxs],\n",
    "                            weight=w[valid_idxs]**2)\n",
    "    \n",
    "    tt = time.time()\n",
    "    xgb_bst = xgb.train(params_xgb,xg_dtrain,\n",
    "                        num_boost_round=int(N_trees_train // theta_dim) + 1,verbose_eval=False)\n",
    "    print(header + 'train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "    tt = time.time()\n",
    "    theta_iter_pred = xgb_bst.predict(xg_dall)\n",
    "    theta_pred.append(theta_iter_pred)\n",
    "    y_remain_train -= w * theta_iter_pred[:N_train]\n",
    "    print(header + 'predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "    \n",
    "theta_pred = np.stack(theta_pred,axis=-1)\n",
    "y_pred = np.sum(X_treat*theta_pred,axis=-1)\n",
    "\n",
    "theta_pred_xgb_mstage,y_pred_xgb_mstage = theta_pred,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. grf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import numpy2ri\n",
    "from rpy2.robjects import r as rapi\n",
    "numpy2ri.activate()\n",
    "grf = importr('grf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stage 0 train time: 50.41s.\n",
      "stage 0 predict time: 2.14s.\n",
      "stage 1 train time: 42.81s.\n",
      "stage 1 predict time: 2.23s.\n",
      "stage 2 train time: 40.52s.\n",
      "stage 2 predict time: 1.85s.\n"
     ]
    }
   ],
   "source": [
    "X_ext_train = X_ext[:N_train]\n",
    "X_treat_train = X_treat[:N_train]\n",
    "y_remain_train = np.expand_dims(y_real[:N_train].copy(),axis=-1)\n",
    "\n",
    "theta_pred = []\n",
    "for iter_ in range(theta_dim):\n",
    "    header = 'stage {} '.format(iter_)\n",
    "    w = X_treat_train[:,[iter_]]\n",
    "    valid_idxs = (np.abs(w[:,0]) > 1e-3)\n",
    "    \n",
    "    tt = time.time()\n",
    "    if np.std(w) < 1e-3:\n",
    "        grf_bst = grf.regression_forest(X_ext_train[valid_idxs],y_remain_train[valid_idxs],\n",
    "                               num_trees=int(N_trees_train // theta_dim) + 1)\n",
    "    else:\n",
    "        grf_bst = grf.causal_forest(X_ext_train[valid_idxs],y_remain_train[valid_idxs],\n",
    "                               w[valid_idxs],num_trees=int(N_trees_train // theta_dim) + 1)\n",
    "    print(header + 'train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "    tt = time.time()\n",
    "    theta_iter_pred = rapi.predict(grf_bst,X_ext)['predictions']\n",
    "    theta_pred.append(theta_iter_pred)\n",
    "    y_remain_train -= w * np.expand_dims(theta_iter_pred[:N_train],axis=-1)\n",
    "    print(header + 'predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "    \n",
    "theta_pred = np.stack(theta_pred,axis=-1)\n",
    "y_pred = np.sum(X_treat*theta_pred,axis=-1)\n",
    "\n",
    "theta_pred_grf,y_pred_grf = theta_pred,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. mbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 160.38s.\n",
      "predict time: 3.02s.\n"
     ]
    }
   ],
   "source": [
    "tt = time.time()\n",
    "mbst,_ = train_multi_bst(params,df_ext.iloc[:N_train].copy(),labels=(X_treat[:N_train],y_real[:N_train]),\n",
    "                         feat_list=feat_list,num_boost_round=N_trees_train,\n",
    "                         obj_func=linear_obj,verbose=False)\n",
    "print('train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "tt = time.time()\n",
    "theta_pred = mbst.predict(X_ext,feat_dict)\n",
    "y_pred = np.sum(X_treat*theta_pred,axis=-1)\n",
    "print('predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "theta_pred_mbst,y_pred_mbst = theta_pred,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. projected mbst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, define a variety of direction finding methods\n",
    "def find_direc_func_null(grad,hess,grad_func,mbst,train_info):\n",
    "    dim = grad.shape[-1]\n",
    "    direc = np.ones((dim,)) / dim\n",
    "    return direc\n",
    "\n",
    "def find_direc_func_grad(grad,hess,grad_func,mbst,train_info):\n",
    "    direc = find_max_var_direc(grad)\n",
    "    return direc\n",
    "\n",
    "def find_direc_func_approx(grad,hess,grad_func,mbst,train_info):\n",
    "    H_sum = np.sum(hess,axis=0)\n",
    "    dtheta_est = np.linalg.solve(H_sum,grad.T).T\n",
    "    direc = find_max_var_direc(dtheta_est)\n",
    "    return direc\n",
    "\n",
    "def find_direc_func_nag(grad,hess,grad_func,mbst,train_info,moment_beta=0.9):\n",
    "    moment = moment_beta * train_info.get('grad_prev',np.zeros(grad.shape))\n",
    "    grad_new,hess_new = grad_func(train_info.get('curr_theta',np.zeros(grad.shape)) \\\n",
    "                                  + train_info.get('delta_theta_mean',np.zeros(grad.shape)) \\\n",
    "                                  + moment * mbst.learning_rate)\n",
    "    grad_new = grad_new + moment\n",
    "    direc = find_max_var_direc(grad_new)\n",
    "    return direc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project mbst (n,c,g)\n",
      "train time: 58.91s.\n",
      "predict time: 3.00s.\n",
      "project mbst (n,c,hg)\n",
      "train time: 56.00s.\n",
      "predict time: 2.84s.\n",
      "project mbst (n,c,nag)\n",
      "train time: 59.40s.\n",
      "predict time: 2.93s.\n",
      "project mbst (pc,c,g)\n",
      "train time: 111.39s.\n",
      "predict time: 2.77s.\n",
      "project mbst (pc,c,hg)\n",
      "train time: 113.16s.\n",
      "predict time: 3.27s.\n",
      "project mbst (pc,c,nag)\n",
      "train time: 118.67s.\n",
      "predict time: 2.55s.\n"
     ]
    }
   ],
   "source": [
    "mbst_projs = []\n",
    "theta_pred_projs = []\n",
    "y_pred_projs = []\n",
    "name_projs = []\n",
    "\n",
    "find_direc_funcs = [\n",
    "#                  ('n',find_direc_func_null),\n",
    "                 ('g',find_direc_func_grad),\n",
    "                ('hg',find_direc_func_approx),\n",
    "                 ('nag',find_direc_func_nag),\n",
    "                ]\n",
    "\n",
    "## then, iterate all possible projected mbst options\n",
    "for corrected_name,corrected in [('n',False),('pc',True)]:\n",
    "#     for centered in [('nc',False),('c',True)]:\n",
    "    for centered_name,centered in [('c',True)]:\n",
    "        for direc_name,find_direc_func in (find_direc_funcs):\n",
    "            name = 'project mbst ({},{},{})'.format(corrected_name,centered_name,direc_name)\n",
    "            print(name)\n",
    "            \n",
    "            tt = time.time()\n",
    "            mbst,_ = train_project_bst(params,df_ext.iloc[:N_train].copy(),\n",
    "                                     labels=(X_treat[:N_train],y_real[:N_train]),\n",
    "                                     feat_list=feat_list,num_boost_round=N_trees_train,\n",
    "                                       find_direc_func=find_direc_func,\n",
    "                                       corrected=corrected,centered=centered,\n",
    "                                     obj_func=linear_obj,verbose=False)\n",
    "            print('train time: {:.2f}s.'.format(time.time() - tt))\n",
    "\n",
    "            tt = time.time()\n",
    "            theta_pred = mbst.predict(X_ext,feat_dict)\n",
    "            y_pred = np.sum(X_treat*theta_pred,axis=-1)\n",
    "            print('predict time: {:.2f}s.'.format(time.time() - tt))\n",
    "            \n",
    "            name_projs.append(name)\n",
    "            mbst_projs.append(mbst)\n",
    "            theta_pred_projs.append(theta_pred)\n",
    "            y_pred_projs.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean baseline</th>\n",
       "      <th>xgb</th>\n",
       "      <th>multi-stage xgb</th>\n",
       "      <th>grf</th>\n",
       "      <th>mbst</th>\n",
       "      <th>project mbst (n,c,g)</th>\n",
       "      <th>project mbst (n,c,hg)</th>\n",
       "      <th>project mbst (n,c,nag)</th>\n",
       "      <th>project mbst (pc,c,g)</th>\n",
       "      <th>project mbst (pc,c,hg)</th>\n",
       "      <th>project mbst (pc,c,nag)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y rmse train</th>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.0348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y rmse test</th>\n",
       "      <td>0.116</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0398</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.0386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta rmse train</th>\n",
       "      <td>[0.0182, 0.1044, 0.0391]</td>\n",
       "      <td>[0.0165, 0.0547, 0.0278]</td>\n",
       "      <td>[0.0127, 0.0388, 0.0179]</td>\n",
       "      <td>[0.014, 0.0508, 0.0239]</td>\n",
       "      <td>[0.0098, 0.0289, 0.0165]</td>\n",
       "      <td>[0.0113, 0.0297, 0.0214]</td>\n",
       "      <td>[0.0113, 0.0298, 0.0215]</td>\n",
       "      <td>[0.0113, 0.0299, 0.0213]</td>\n",
       "      <td>[0.0109, 0.0297, 0.0199]</td>\n",
       "      <td>[0.0109, 0.0297, 0.02]</td>\n",
       "      <td>[0.0108, 0.0297, 0.02]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta rmse test</th>\n",
       "      <td>[0.0181, 0.1042, 0.0392]</td>\n",
       "      <td>[0.0164, 0.055, 0.0279]</td>\n",
       "      <td>[0.0126, 0.0397, 0.0182]</td>\n",
       "      <td>[0.014, 0.0527, 0.0245]</td>\n",
       "      <td>[0.0098, 0.0299, 0.0167]</td>\n",
       "      <td>[0.0113, 0.031, 0.0215]</td>\n",
       "      <td>[0.0112, 0.031, 0.0217]</td>\n",
       "      <td>[0.0113, 0.0311, 0.0214]</td>\n",
       "      <td>[0.0109, 0.031, 0.02]</td>\n",
       "      <td>[0.011, 0.0309, 0.0201]</td>\n",
       "      <td>[0.0108, 0.0308, 0.0201]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta corr train</th>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.5277, 0.8752, 0.7576]</td>\n",
       "      <td>[0.7222, 0.9323, 0.8964]</td>\n",
       "      <td>[0.6684, 0.8819, 0.817]</td>\n",
       "      <td>[0.8495, 0.9618, 0.9095]</td>\n",
       "      <td>[0.7945, 0.9592, 0.8409]</td>\n",
       "      <td>[0.797, 0.9591, 0.838]</td>\n",
       "      <td>[0.7963, 0.9587, 0.8423]</td>\n",
       "      <td>[0.8144, 0.9592, 0.8646]</td>\n",
       "      <td>[0.8111, 0.9593, 0.8632]</td>\n",
       "      <td>[0.8147, 0.9594, 0.8636]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>theta corr test</th>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.522, 0.8715, 0.7568]</td>\n",
       "      <td>[0.7207, 0.9281, 0.8926]</td>\n",
       "      <td>[0.6666, 0.869, 0.8054]</td>\n",
       "      <td>[0.8468, 0.9588, 0.9071]</td>\n",
       "      <td>[0.7917, 0.9552, 0.8395]</td>\n",
       "      <td>[0.7941, 0.9553, 0.8364]</td>\n",
       "      <td>[0.7919, 0.955, 0.8408]</td>\n",
       "      <td>[0.8104, 0.9553, 0.8635]</td>\n",
       "      <td>[0.8069, 0.9556, 0.8618]</td>\n",
       "      <td>[0.8119, 0.9559, 0.8626]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean baseline                       xgb  \\\n",
       "y rmse train                        0.1147                    0.0594   \n",
       "y rmse test                          0.116                    0.0656   \n",
       "theta rmse train  [0.0182, 0.1044, 0.0391]  [0.0165, 0.0547, 0.0278]   \n",
       "theta rmse test   [0.0181, 0.1042, 0.0392]   [0.0164, 0.055, 0.0279]   \n",
       "theta corr train           [0.0, 0.0, 0.0]  [0.5277, 0.8752, 0.7576]   \n",
       "theta corr test            [0.0, 0.0, 0.0]   [0.522, 0.8715, 0.7568]   \n",
       "\n",
       "                           multi-stage xgb                      grf  \\\n",
       "y rmse train                        0.0413                   0.0515   \n",
       "y rmse test                          0.046                   0.0606   \n",
       "theta rmse train  [0.0127, 0.0388, 0.0179]  [0.014, 0.0508, 0.0239]   \n",
       "theta rmse test   [0.0126, 0.0397, 0.0182]  [0.014, 0.0527, 0.0245]   \n",
       "theta corr train  [0.7222, 0.9323, 0.8964]  [0.6684, 0.8819, 0.817]   \n",
       "theta corr test   [0.7207, 0.9281, 0.8926]  [0.6666, 0.869, 0.8054]   \n",
       "\n",
       "                                      mbst      project mbst (n,c,g)  \\\n",
       "y rmse train                         0.032                    0.0358   \n",
       "y rmse test                         0.0359                    0.0398   \n",
       "theta rmse train  [0.0098, 0.0289, 0.0165]  [0.0113, 0.0297, 0.0214]   \n",
       "theta rmse test   [0.0098, 0.0299, 0.0167]   [0.0113, 0.031, 0.0215]   \n",
       "theta corr train  [0.8495, 0.9618, 0.9095]  [0.7945, 0.9592, 0.8409]   \n",
       "theta corr test   [0.8468, 0.9588, 0.9071]  [0.7917, 0.9552, 0.8395]   \n",
       "\n",
       "                     project mbst (n,c,hg)    project mbst (n,c,nag)  \\\n",
       "y rmse train                        0.0358                    0.0358   \n",
       "y rmse test                         0.0398                    0.0398   \n",
       "theta rmse train  [0.0113, 0.0298, 0.0215]  [0.0113, 0.0299, 0.0213]   \n",
       "theta rmse test    [0.0112, 0.031, 0.0217]  [0.0113, 0.0311, 0.0214]   \n",
       "theta corr train    [0.797, 0.9591, 0.838]  [0.7963, 0.9587, 0.8423]   \n",
       "theta corr test   [0.7941, 0.9553, 0.8364]   [0.7919, 0.955, 0.8408]   \n",
       "\n",
       "                     project mbst (pc,c,g)    project mbst (pc,c,hg)  \\\n",
       "y rmse train                        0.0347                    0.0348   \n",
       "y rmse test                         0.0388                    0.0388   \n",
       "theta rmse train  [0.0109, 0.0297, 0.0199]    [0.0109, 0.0297, 0.02]   \n",
       "theta rmse test      [0.0109, 0.031, 0.02]   [0.011, 0.0309, 0.0201]   \n",
       "theta corr train  [0.8144, 0.9592, 0.8646]  [0.8111, 0.9593, 0.8632]   \n",
       "theta corr test   [0.8104, 0.9553, 0.8635]  [0.8069, 0.9556, 0.8618]   \n",
       "\n",
       "                   project mbst (pc,c,nag)  \n",
       "y rmse train                        0.0348  \n",
       "y rmse test                         0.0386  \n",
       "theta rmse train    [0.0108, 0.0297, 0.02]  \n",
       "theta rmse test   [0.0108, 0.0308, 0.0201]  \n",
       "theta corr train  [0.8147, 0.9594, 0.8636]  \n",
       "theta corr test   [0.8119, 0.9559, 0.8626]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def rounding(l,decimals=4):\n",
    "    return list(np.round(l,decimals=decimals))\n",
    "\n",
    "method_names = ['mean baseline','xgb','multi-stage xgb','grf','mbst'] + name_projs\n",
    "y_preds = [np.mean(y_real),y_pred_xgb_base,y_pred_xgb_mstage,y_pred_grf,y_pred_mbst] + y_pred_projs\n",
    "theta_preds = [np.mean(theta_real,axis=0),theta_pred_xgb_base,theta_pred_xgb_mstage,\n",
    "               theta_pred_grf,theta_pred_mbst] \\\n",
    "                + theta_pred_projs\n",
    "\n",
    "y_train_rmse = [np.sqrt(np.mean(np.square(y_pred - y_real)[:N_train])) for y_pred in y_preds]\n",
    "y_test_rmse = [np.sqrt(np.mean(np.square(y_pred - y_real)[N_train:])) for y_pred in y_preds]\n",
    "theta_train_rmse = [np.sqrt(np.mean(np.square(theta_pred - theta_real)[:N_train],axis=0)) \n",
    "                    for theta_pred in theta_preds]\n",
    "theta_test_rmse = [np.sqrt(np.mean(np.square(theta_pred - theta_real)[N_train:],axis=0)) \n",
    "                   for theta_pred in theta_preds]\n",
    "theta_train_corr = [np.zeros((theta_dim,))] + \\\n",
    "                    [np.array([np.corrcoef(theta_pred[:,col][:N_train], \n",
    "                                          theta_real[:,col][:N_train])[0,1] for col in range(theta_dim)]) \n",
    "                    for theta_pred in theta_preds[1:]]\n",
    "theta_test_corr = [np.zeros((theta_dim,))] + \\\n",
    "                    [np.array([np.corrcoef(theta_pred[:,col][N_train:], \n",
    "                                          theta_real[:,col][N_train:])[0,1] for col in range(theta_dim)]) \n",
    "                    for theta_pred in theta_preds[1:]]\n",
    "\n",
    "err_df = pd.DataFrame({'y rmse train':rounding(y_train_rmse),'y rmse test':rounding(y_test_rmse),\n",
    "                   'theta rmse train':rounding(theta_train_rmse),'theta rmse test':rounding(theta_test_rmse),\n",
    "                   'theta corr train':rounding(theta_train_corr),'theta corr test':rounding(theta_test_corr),})\n",
    "err_df = err_df.T\n",
    "err_df.columns = method_names\n",
    "display(err_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
